{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### **7.5 Singular Value Decomposition (SVD), Positive Definite Matrices, and Gradient Descent for Optimization**\n",
    "\n",
    "For a symmetrix matrix $S = X\\Lambda X^{T} = x_1\\lambda_1 x_1^{T}+...+x_n\\lambda_n x_n^{T}$\n",
    "\\begin{aligned}\n",
    "8x_1 + 2x_2 + 3x_3   &=& 14 \\\\\n",
    "2x_1 - 8x_2 + 5x_3  &=& 5 \\\\\n",
    "3x_1 + 5x_2 + 10x_3 & =& -8 \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<font color=\"magenta\">**TRY IT!**</font> Compute the eigenvalues and eigenvectors for matrix $S = \\begin{bmatrix}\n",
    "8 & 2 &  3\\\\\n",
    "2 & -8 & 5\\\\\n",
    "3 & 5 & 10\\\\\n",
    "\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-value w: [13.4487556   5.93016383 -9.37891943]\n",
      "\n",
      "E-vector v: \n",
      "[[ 0.53416162  0.84246306  0.07019516]\n",
      " [ 0.23884925 -0.07074704 -0.96847607]\n",
      " [ 0.81093921 -0.53408881  0.23901203]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.1: Review of eigenvalues, eigenvectors with a 3 by 3 symmetric matrix S\n",
    "\"\"\"\n",
    "##########################################################\n",
    "### 1. eigenvalue/eigenvector for a symmetric matrix S ###\n",
    "##########################################################\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "\n",
    "S = np.array([[8,  2,  3], \n",
    "              [2, -8,  5],\n",
    "              [3,  5, 10]])\n",
    "w, v = eig(S) \n",
    "v = v*np.sign(v[0,0])     # remove the sign of ambiguity\n",
    "print(f\"E-value w: {w}\\n\")\n",
    "print(f\"E-vector v: \\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are orthogonal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "### 2. check orthogonality of eigenvectors of symmetric matrix S ###\n",
    "####################################################################\n",
    "\n",
    "def check_orthogonality(A, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Checks whether the columns of matrix A are orthogonal.\n",
    "    :param A: Input matrix (numpy array)\n",
    "    :param tol: Tolerance for numerical precision\n",
    "    :return: True if columns are orthogonal, False otherwise\n",
    "    \"\"\"\n",
    "    n = A.shape[1]  # Number of columns\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dot_product = np.dot(A[:, i], A[:, j])\n",
    "            if abs(dot_product) > tol:\n",
    "                print(f\"Columns {i+1} and {j+1} are NOT orthogonal (dot product: {dot_product:.6f})\")\n",
    "                return False\n",
    "    print(\"Columns are orthogonal.\")\n",
    "    return True\n",
    "\n",
    "# Check orthogonality\n",
    "check_orthogonality(v)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= \"cyan\">**7.5.1 Singular Value Decomposition (SVD) in Python**</font>\n",
    "$A = U\\Sigma V^{T} = u_1\\sigma_1 v_1^{T}+...+ u_n\\sigma_n v_n^{T}$\n",
    "\n",
    "$S = X\\Lambda X^{T} = x_1\\lambda_1 x_1^{T}+...+x_n\\lambda_n x_n^{T}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U = \n",
      "[[-0.53416162  0.07019516 -0.84246306]\n",
      " [-0.23884925 -0.96847607  0.07074704]\n",
      " [-0.81093921  0.23901203  0.53408881]]\n",
      "\n",
      "Sigma = \n",
      "[13.4487556   9.37891943  5.93016383]\n",
      "\n",
      "VH = \n",
      "[[-0.53416162 -0.23884925 -0.81093921]\n",
      " [-0.07019516  0.96847607 -0.23901203]\n",
      " [-0.84246306  0.07074704  0.53408881]]\n",
      "\n",
      "condition number of matrix S is: 2.267855661326328\n",
      "\n",
      "ratio of singular value is: 2.267855661326327\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.2: SVD and Condition number of Matrix A\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from numpy.linalg import eig, cond, svd\n",
    "\n",
    "S = np.array([[8,  2,  3], \n",
    "              [2, -8,  5],\n",
    "              [3,  5, 10]])\n",
    "\n",
    "U, Sigma, VH = np.linalg.svd(S)\n",
    "\n",
    "print(f\"U = \\n{U}\\n\")\n",
    "print(f\"Sigma = \\n{Sigma}\\n\")\n",
    "print(f\"VH = \\n{VH}\\n\")\n",
    "\n",
    "\n",
    "######### check the matrix condition number through SVD #################\n",
    "\n",
    "print(f\"condition number of matrix S is: {cond(S)}\\n\")\n",
    "print(f\"ratio of singular value is: {Sigma[0]/Sigma[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= \"cyan\">**7.5.2 Positive Definite Matrices $A^{T}A$**</font>\n",
    "For a general matrix $Ax =b$\n",
    "\\begin{aligned}\n",
    "1x_1 + 0x_2    &=& 6 \\\\\n",
    "1x_1 + 1x_2    &=& 0 \\\\\n",
    "1x_1 + 2x_2    &=& 0 \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "**TRY IT!** Compute the eigenvalues and eigenvectors for matrix $A = \\begin{bmatrix}\n",
    "1 & 0  \\\\\n",
    "1 & 1  \\\\\n",
    "1 & 2  \\\\\n",
    "\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-value w: [0.83772234 7.16227766]\n",
      "\n",
      "E-vector v: \n",
      "[[ 0.81124219  0.58471028]\n",
      " [-0.58471028  0.81124219]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.3: eigenvalues, eigenvectors with a 3 by 3 positive definite matrix A^TA\n",
    "\"\"\"\n",
    "##################################################################\n",
    "### 1. eigenvalue/eigenvector for a positive definite matrix S ###\n",
    "##################################################################\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "\n",
    "A = np.array([[1,  0], \n",
    "              [1,  1],\n",
    "              [1,  2]])\n",
    "S = A.T @ A\n",
    "w, v = eig(S) \n",
    "v = v*np.sign(v[0,0])            # remove the sign of ambiguity\n",
    "print(f\"E-value w: {w}\\n\")       # all positive e-values\n",
    "print(f\"E-vector v: \\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U = \n",
      "[[-0.58471028 -0.81124219]\n",
      " [-0.81124219  0.58471028]]\n",
      "\n",
      "Sigma = \n",
      "[7.16227766 0.83772234]\n",
      "\n",
      "VH = \n",
      "[[-0.58471028 -0.81124219]\n",
      " [-0.81124219  0.58471028]]\n",
      "\n",
      "condition number of matrix S is: 8.549703546891168\n",
      "\n",
      "ratio of singular value is: 8.54970354689117\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.4: SVD and Condition number of Positive definite Matrix S\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from numpy.linalg import eig, cond, svd\n",
    "\n",
    "A = np.array([[1,  0], \n",
    "              [1,  1],\n",
    "              [1,  2]])\n",
    "S = A.T @ A\n",
    "\n",
    "U, Sigma, VH = np.linalg.svd(S)\n",
    "\n",
    "print(f\"U = \\n{U}\\n\")\n",
    "print(f\"Sigma = \\n{Sigma}\\n\")\n",
    "print(f\"VH = \\n{VH}\\n\")\n",
    "\n",
    "######### check the matrix condition number through SVD #################\n",
    "print(f\"condition number of matrix S is: {cond(S)}\\n\")\n",
    "print(f\"ratio of singular value is: {Sigma[0]/Sigma[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= \"cyan\">**7.5.3 Optimization and Gradient Descent Method**</font>\n",
    "\n",
    "\\begin{aligned}\n",
    "1x_1 + 0x_2   &=& 6 \\\\\n",
    "1x_1 + 1x_2   &=& 0 \\\\\n",
    "1x_1 + 2x_2   &=& 0 \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "A is a 3 by 2 matrix (more rows than columns), this is an over-determined system. \n",
    "\n",
    "The system may not have an exact solution, so we typically find the <font color=cyan> *Least Squares Solution* </font> that minimizes $J(x) = ||Ax-b||^2$. Let's compute the solution now. \n",
    "\n",
    "\\begin{aligned}\n",
    " J(x) &= \\frac{1}{2}||Ax-b||^2 \\\\\n",
    "      &= \\frac{1}{2}{(Ax-b)^T(Ax-b)} \\\\\n",
    "      &= \\frac{1}{2}{(x^TA^TAx-2x^TA^Tb+b^Tb)}\\\\\n",
    "      &= \\frac{1}{2}{x^TA^TAx}-x^TA^Tb+ \\frac{1}{2}{b^Tb}\\\\\n",
    "\\\\\n",
    "\n",
    "\\nabla{J(x)} &= AA^Tx -A^Tb = 0 \\\\    \n",
    "\\\\\n",
    "AA^Tx &= A^Tb \n",
    "\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the optimization problem leads to the classical $Sx = b'$ problem, now $S = A^TA$ is a positice definite matrix, $b' = A^Tb$ is the new vector. \n",
    "\\begin{aligned}\n",
    "Sx = b'\n",
    "\\end{aligned}\n",
    "\n",
    "This $Sx = b'$ problem can be solved by the numerical gradient descent method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution x is = [ 5. -3.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.5: Optimization to find the least square solution\n",
    "\"\"\"\n",
    "\n",
    "A = np.array([[1,  0], \n",
    "              [1,  1],\n",
    "              [1,  2]])\n",
    "b = np.array([6, 0, 0])\n",
    "\n",
    "S = A.T @ A\n",
    "b_new = A.T @ b\n",
    "\n",
    "x = np.linalg.pinv(S) @ b_new\n",
    "print(f\"solution x is = {x} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x: [ 4.99994296 -2.99995889]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 7.5.6: Optimization by gradient descent\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def gradient_descent(A, b, x_init, learning_rate=0.01, tol=1e-6, max_iter=1000):\n",
    "    x = x_init\n",
    "    for i in range(max_iter):\n",
    "        gradient = 2 * A.T @ (A @ x - b)  # Compute gradient\n",
    "        x_new = x - learning_rate * gradient  # Update step\n",
    "        \n",
    "        if np.linalg.norm(x_new - x, ord=2) < tol:  # Convergence check\n",
    "            break\n",
    "        x = x_new\n",
    "    return x\n",
    "\n",
    "# Example 2x2 system\n",
    "\n",
    "x_init = np.zeros(2)  # Initial guess\n",
    "solution = gradient_descent(S, b_new, x_init)\n",
    "print(\"Solution x:\", solution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerical_methods_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
